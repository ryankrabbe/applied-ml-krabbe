{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "925bf6ec",
   "metadata": {},
   "source": [
    "# Ryan's Lab 4 Project\n",
    "**Author:** Ryan Krabbe  \n",
    "**Date:** 4/08/2025\n",
    "\n",
    "**Objective:** Use the Titantic dataset to predict `fare` using different regression models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678a384e",
   "metadata": {},
   "source": [
    "## Imports\n",
    "In the code cell below, import the necessary Python libraries for this notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1607d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    BaggingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f34314",
   "metadata": {},
   "source": [
    "## Section 1. Load and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cd813f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"winequality-red.csv\", sep=\";\")\n",
    "\n",
    "# Display structure and first few rows\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4f9adc",
   "metadata": {},
   "source": [
    "## Section 2. Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aad7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the variable target, quality into three categories: low (3–4), medium (5–6), high (7–8) to make classification feasible\n",
    "def quality_to_label(q):\n",
    "    if q <= 4:\n",
    "        return \"low\"\n",
    "    elif q <= 6:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "\n",
    "# Call the apply() method on the quality column to create the new quality_label column\n",
    "df[\"quality_label\"] = df[\"quality\"].apply(quality_to_label)\n",
    "    \n",
    "# create a numeric column for modeling 0 = low, 1 = medium, 2 = high\n",
    "def quality_to_number(q):\n",
    "    if q <= 4:\n",
    "        return 0\n",
    "    elif q <= 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# Call the apply() method on the quality column to create the new quality_numeric column    \n",
    "df[\"quality_numeric\"] = df[\"quality\"].apply(quality_to_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa34a77",
   "metadata": {},
   "source": [
    "## Section 3. Feature Selection and Justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea0cc767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input features (X) and target (y)\n",
    "# Features: all columns except 'quality' and 'quality_label' and 'quality_numberic' - drop these from the input array\n",
    "\n",
    "X = df.drop(columns=[\"quality\", \"quality_label\", \"quality_numeric\"])  # Features\n",
    "y = df[\"quality_numeric\"]  # Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dff98f3",
   "metadata": {},
   "source": [
    "## Section 4. Split the Data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4f66333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split (stratify to preserve class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dfaad2",
   "metadata": {},
   "source": [
    "## Section 5.  Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12cdd9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to train and evaluate models\n",
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test, results):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, average=\"weighted\")\n",
    "    test_f1 = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
    "\n",
    "    print(f\"\\n{name} Results\")\n",
    "    print(\"Confusion Matrix (Test):\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Train F1 Score: {train_f1:.4f}, Test F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"Model\": name,\n",
    "            \"Train Accuracy\": train_acc,\n",
    "            \"Test Accuracy\": test_acc,\n",
    "            \"Train F1\": train_f1,\n",
    "            \"Test F1\": test_f1,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bc08a1",
   "metadata": {},
   "source": [
    "### Choose 2 models to run. I chose Gradient Boosting & Voting (RF + LR + KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76d9d7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting (100) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  3 247  14]\n",
      " [  0  16  27]]\n",
      "Train Accuracy: 0.9601, Test Accuracy: 0.8562\n",
      "Train F1 Score: 0.9584, Test F1 Score: 0.8411\n",
      "\n",
      "Voting (RF + LR + KNN) Results\n",
      "Confusion Matrix (Test):\n",
      "[[  0  13   0]\n",
      " [  0 257   7]\n",
      " [  0  27  16]]\n",
      "Train Accuracy: 0.9132, Test Accuracy: 0.8531\n",
      "Train F1 Score: 0.8929, Test F1 Score: 0.8210\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Evaluate Gradient Boosting Model with 100 tries\n",
    "evaluate_model(\n",
    "    \"Gradient Boosting (100)\",\n",
    "    GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")\n",
    "\n",
    "# Define Voting (RF + LR + KNN) model\n",
    "voting2 = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', RandomForestClassifier(n_estimators=100)),\n",
    "        ('lr', LogisticRegression(max_iter=2000)),\n",
    "        ('knn', KNeighborsClassifier())\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "evaluate_model(\n",
    "    \"Voting (RF + LR + KNN)\",\n",
    "    voting2,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc32f24",
   "metadata": {},
   "source": [
    "## Section 6. Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b1a2ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of All Models (Sorted by Test Accuracy, with Gaps):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Test F1</th>\n",
       "      <th>Accuracy Gap</th>\n",
       "      <th>F1 Gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting (100)</td>\n",
       "      <td>0.960125</td>\n",
       "      <td>0.856250</td>\n",
       "      <td>0.958410</td>\n",
       "      <td>0.841106</td>\n",
       "      <td>0.103875</td>\n",
       "      <td>0.117304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Voting (RF + LR + KNN)</td>\n",
       "      <td>0.913213</td>\n",
       "      <td>0.853125</td>\n",
       "      <td>0.892945</td>\n",
       "      <td>0.821034</td>\n",
       "      <td>0.060088</td>\n",
       "      <td>0.071911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Train Accuracy  Test Accuracy  Train F1   Test F1  \\\n",
       "0  Gradient Boosting (100)        0.960125       0.856250  0.958410  0.841106   \n",
       "1   Voting (RF + LR + KNN)        0.913213       0.853125  0.892945  0.821034   \n",
       "\n",
       "   Accuracy Gap    F1 Gap  \n",
       "0      0.103875  0.117304  \n",
       "1      0.060088  0.071911  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Add gap columns based on actual keys\n",
    "results_df[\"Accuracy Gap\"] = results_df[\"Train Accuracy\"] - results_df[\"Test Accuracy\"]\n",
    "results_df[\"F1 Gap\"] = results_df[\"Train F1\"] - results_df[\"Test F1\"]\n",
    "\n",
    "# Sort by test accuracy\n",
    "results_df_sorted = results_df.sort_values(by=\"Test Accuracy\", ascending=False)\n",
    "\n",
    "# Display sorted results\n",
    "print(\"\\nSummary of All Models (Sorted by Test Accuracy, with Gaps):\")\n",
    "display(results_df_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a355ae5",
   "metadata": {},
   "source": [
    "## Section 7. Conclusion and Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477fd086",
   "metadata": {},
   "source": [
    "## Comparing Gradient Boosting model & Voting (RF + LR + KNN) model\n",
    "\n",
    "**Gradient Boosting**\n",
    "- Test Accuracy: 85.6%\n",
    "- Test F1: 84.1%\n",
    "\n",
    "**Conclusion**: The Gradient Boosting model performed better than the Voting model indicated by the Test Accuracy and Test F1 scores. This model performed well on the complex patterns in the dataset, but showed some signs of overfitting. Overeall, the model performed much better on the training data than the test data.\n",
    "\n",
    "**Voting (RF + LR + KNN)**\n",
    "- Test Accuracy: 85.3%\n",
    "- Test F1: 82.1%\n",
    "\n",
    "**Conclusion**: Although the Voting model scores were lower than the Gradient Boosting scores the model still performed quite well. By adding the gap scores I was able to see how this model might've outperformed the Gradient Boosting model in some aspects. There are smaller gaps within this model meaning that it's less likely to overfit and may perform better in the future on unseen data. While the Gradient Boosting model's raw scores were better the Voting model ws more consistent between the training and test data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
